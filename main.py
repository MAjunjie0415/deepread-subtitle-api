from flask import Flask, request, jsonify
from youtube_transcript_api import YouTubeTranscriptApi
import yt_dlp
import re
import json

app = Flask(__name__)

def get_video_id(url):
    """ä» YouTube URL æå–è§†é¢‘ ID"""
    m = re.search(r"v=([a-zA-Z0-9_-]{11})", url)
    return m.group(1) if m else None

def fetch_subtitle_from_url(url):
    """ä» URL è·å–å­—å¹•å†…å®¹"""
    try:
        import urllib.request
        with urllib.request.urlopen(url) as response:
            data = json.loads(response.read().decode('utf-8'))
            
        if 'events' in data:
            segments = []
            for event in data['events']:
                if 'segs' in event:
                    text = ''.join([seg.get('utf8', '') for seg in event['segs']]).strip()
                    if text:
                        segments.append({
                            'text': text,
                            'start': event.get('tStartMs', 0) / 1000,
                            'duration': event.get('dDurationMs', 0) / 1000
                        })
            return segments
        return None
    except Exception as e:
        print(f"   âš ï¸ è·å–å­—å¹• URL å¤±è´¥: {str(e)}")
        return None

@app.route("/", methods=["GET"])
def home():
    """å¥åº·æ£€æŸ¥ç«¯ç‚¹"""
    return jsonify({
        "status": "ok",
        "service": "DeepRead Subtitle API",
        "version": "1.0.0"
    })

@app.route("/extract", methods=["POST"])
def extract():
    """æå– YouTube å­—å¹• - ä½¿ç”¨åç«¯é…ç½®çš„ Cookie"""
    import os
    
    url = request.json.get("url", "")
    vid = get_video_id(url)
    
    if not vid:
        return jsonify({"error": "Invalid YouTube URL"}), 400

    # ä»ç¯å¢ƒå˜é‡è·å– YouTube Cookies
    youtube_cookies_raw = os.environ.get("YOUTUBE_COOKIES", "")
    youtube_cookies_base64 = os.environ.get("YOUTUBE_COOKIES_BASE64", "")
    
    # ä¼˜å…ˆä½¿ç”¨ Base64 ç¼–ç çš„ cookiesï¼ˆé¿å…æ¢è¡Œç¬¦é—®é¢˜ï¼‰
    youtube_cookies = ""
    if youtube_cookies_base64:
        try:
            import base64
            youtube_cookies = base64.b64decode(youtube_cookies_base64).decode('utf-8')
            print(f"ğŸ”“ ä½¿ç”¨ Base64 è§£ç çš„ Cookies")
        except Exception as e:
            print(f"âš ï¸  Base64 è§£ç å¤±è´¥: {e}")
    
    # å¦‚æœæ²¡æœ‰ Base64ï¼Œä½¿ç”¨åŸå§‹å€¼
    if not youtube_cookies and youtube_cookies_raw:
        youtube_cookies = youtube_cookies_raw
    
    try:
        print(f"\n{'='*60}")
        print(f"ğŸ¯ å¼€å§‹æå–å­—å¹•")
        print(f"ğŸ“¹ è§†é¢‘ ID: {vid}")
        print(f"ğŸª Cookies çŠ¶æ€: {'å·²é…ç½®' if youtube_cookies else 'æœªé…ç½®'}")
        if youtube_cookies:
            print(f"ğŸª Cookies é•¿åº¦: {len(youtube_cookies)} å­—ç¬¦")
            print(f"ğŸª Cookies å‰ 100 å­—ç¬¦: {youtube_cookies[:100]}")
        print(f"{'='*60}")
        
        # è·å–å®Œæ•´å­—å¹•ï¼ˆè‡ªåŠ¨ç¿»é¡µï¼‰
        segments = []
        page = 0
        
        # ç­–ç•¥ 1: ä½¿ç”¨ yt-dlp (æœ€å¼ºå¤§ï¼Œèƒ½ç»•è¿‡é™åˆ¶)
        try:
            print(f"\nğŸš€ æ–¹æ³• 1: ä½¿ç”¨ yt-dlp æå–å­—å¹•...")
            
            ydl_opts = {
                'skip_download': True,
                'writesubtitles': True,
                'writeautomaticsub': True,
                'subtitleslangs': ['en', 'en-US', 'en-GB'],
                'subtitlesformat': 'json3',
                'quiet': True,
                'no_warnings': True,
            }
            
            # å¦‚æœé…ç½®äº† cookiesï¼Œå†™å…¥ä¸´æ—¶æ–‡ä»¶
            import tempfile
            import os as os_module
            cookie_file_path = None
            if youtube_cookies:
                print(f"   ğŸª ä½¿ç”¨é…ç½®çš„ YouTube Cookies")
                
                # åˆ›å»ºä¸´æ—¶æ–‡ä»¶
                fd, cookie_file_path = tempfile.mkstemp(suffix='.txt', text=True)
                
                # å†™å…¥ cookies
                with os_module.fdopen(fd, 'w') as f:
                    f.write(youtube_cookies)
                    f.flush()
                
                print(f"   ğŸ“ Cookies æ–‡ä»¶å·²å†™å…¥: {cookie_file_path}")
                
                # éªŒè¯æ–‡ä»¶
                with open(cookie_file_path, 'r') as f:
                    content = f.read()
                    lines = content.split('\n')
                    cookie_lines = [l for l in lines if l and not l.startswith('#')]
                    print(f"   âœ“ Cookie æ–‡ä»¶è¡Œæ•°: {len(lines)}ï¼Œæœ‰æ•ˆ cookie è¡Œæ•°: {len(cookie_lines)}")
                
                ydl_opts['cookiefile'] = cookie_file_path
            
            with yt_dlp.YoutubeDL(ydl_opts) as ydl:
                info = ydl.extract_info(f"https://www.youtube.com/watch?v={vid}", download=False)
                
                # è·å–å­—å¹•
                if 'subtitles' in info and info['subtitles']:
                    print(f"ğŸ“‹ æ‰¾åˆ°æ‰‹åŠ¨å­—å¹•: {list(info['subtitles'].keys())}")
                    # ä¼˜å…ˆä½¿ç”¨æ‰‹åŠ¨å­—å¹•
                    for lang in ['en', 'en-US', 'en-GB']:
                        if lang in info['subtitles']:
                            subtitle_url = info['subtitles'][lang][0]['url']
                            print(f"âœ… ä½¿ç”¨æ‰‹åŠ¨å­—å¹•: {lang}")
                            segments = fetch_subtitle_from_url(subtitle_url)
                            if segments:
                                break
                
                elif 'automatic_captions' in info and info['automatic_captions']:
                    print(f"ğŸ“‹ æ‰¾åˆ°è‡ªåŠ¨å­—å¹•: {list(info['automatic_captions'].keys())}")
                    # ä½¿ç”¨è‡ªåŠ¨å­—å¹•
                    for lang in ['en', 'en-US', 'en-GB']:
                        if lang in info['automatic_captions']:
                            # æ‰¾åˆ° json3 æ ¼å¼çš„å­—å¹•
                            for subtitle in info['automatic_captions'][lang]:
                                if subtitle.get('ext') == 'json3':
                                    subtitle_url = subtitle['url']
                                    print(f"âœ… ä½¿ç”¨è‡ªåŠ¨å­—å¹•: {lang}")
                                    segments = fetch_subtitle_from_url(subtitle_url)
                                    if segments:
                                        break
                            if segments:
                                break
                
                if segments:
                    print(f"âœ… yt-dlp æˆåŠŸ: {len(segments)} æ®µ")
                else:
                    raise Exception("yt-dlp æœªæ‰¾åˆ°å­—å¹•")
            
            # æ¸…ç†ä¸´æ—¶ cookie æ–‡ä»¶
            if cookie_file_path:
                try:
                    os_module.unlink(cookie_file_path)
                    print(f"   ğŸ—‘ï¸  å·²æ¸…ç†ä¸´æ—¶ cookie æ–‡ä»¶")
                except:
                    pass
                    
        except Exception as e1:
            print(f"âŒ yt-dlp å¤±è´¥: {str(e1)}")
            
            # ç­–ç•¥ 2: å¤‡ç”¨ youtube-transcript-api
            try:
                print(f"\nğŸ”„ æ–¹æ³• 2: ä½¿ç”¨ youtube-transcript-api...")
                transcript_list = YouTubeTranscriptApi.list_transcripts(vid)
                
                # ä¼˜å…ˆé€‰æ‹©è‹±è¯­å­—å¹•
                selected_transcript = None
                for transcript in transcript_list:
                    if transcript.language_code in ['en', 'en-US', 'en-GB']:
                        selected_transcript = transcript
                        break
                
                if not selected_transcript:
                    selected_transcript = list(transcript_list)[0]
                
                segments = selected_transcript.fetch()
                print(f"âœ… youtube-transcript-api æˆåŠŸ: {len(segments)} æ®µ")
                
            except Exception as e2:
                error_msg = f"æ‰€æœ‰æ–¹æ³•éƒ½å¤±è´¥äº†ã€‚yt-dlp: {str(e1)}; transcript-api: {str(e2)}"
                print(f"\nâŒ {error_msg}")
                return jsonify({"error": error_msg}), 404
        
        # æ ¼å¼åŒ–è¾“å‡º
        full_text = " ".join([s["text"] for s in segments])
        
        # æ ¼å¼åŒ–ä¸ºæ ‡å‡†æ ¼å¼
        formatted_segments = []
        for idx, seg in enumerate(segments):
            formatted_segments.append({
                "segment_id": f"seg_{str(idx).zfill(4)}",
                "start": seg["start"],
                "duration": seg["duration"],
                "end": seg["start"] + seg["duration"],
                "timestamp": format_timestamp(seg["start"]),
                "text": seg["text"]
            })
        
        # ç»Ÿè®¡ä¿¡æ¯
        total_duration = segments[-1]["start"] + segments[-1]["duration"] if segments else 0
        word_count = len(full_text.split())
        
        print(f"\n{'='*60}")
        print(f"âœ… æå–æˆåŠŸï¼")
        print(f"ğŸ“ æ€»æ®µæ•°: {len(formatted_segments)}")
        print(f"ğŸ’¬ æ€»å­—æ•°: {word_count}")
        print(f"â±ï¸  æ—¶é•¿: {format_timestamp(total_duration)}")
        print(f"{'='*60}\n")
        
        return jsonify({
            "success": True,
            "video_id": vid,
            "transcript": formatted_segments,
            "meta": {
                "segment_count": len(formatted_segments),
                "word_count": word_count,
                "duration_seconds": total_duration,
                "duration_formatted": format_timestamp(total_duration),
                "source": "youtube_transcript_api"
            }
        })
        
    except Exception as e:
        print(f"\nâŒ é”™è¯¯: {str(e)}\n")
        return jsonify({"error": str(e)}), 500

def format_timestamp(seconds):
    """æ ¼å¼åŒ–æ—¶é—´æˆ³"""
    hours = int(seconds // 3600)
    minutes = int((seconds % 3600) // 60)
    secs = int(seconds % 60)
    
    if hours > 0:
        return f"{hours}:{str(minutes).zfill(2)}:{str(secs).zfill(2)}"
    return f"{minutes}:{str(secs).zfill(2)}"

if __name__ == "__main__":
    # ç›‘å¬ 0.0.0.0 æ–¹ä¾¿å®¹å™¨è®¿é—®
    # Zeabur ä½¿ç”¨ 8080 ç«¯å£
    port = 8080
    print("\nğŸš€ DeepRead Subtitle API å¯åŠ¨ä¸­...")
    print(f"ğŸ“¡ ç›‘å¬ç«¯å£: {port}")
    print("="*60 + "\n")
    app.run(host="0.0.0.0", port=port, debug=False)

