from flask import Flask, request, jsonify
from youtube_transcript_api import YouTubeTranscriptApi
import yt_dlp
import re
import json

app = Flask(__name__)

def get_video_id(url):
    """ä» YouTube URL æå–è§†é¢‘ ID"""
    m = re.search(r"v=([a-zA-Z0-9_-]{11})", url)
    return m.group(1) if m else None

def fetch_subtitle_from_url(url):
    """ä» URL è·å–å­—å¹•å†…å®¹"""
    try:
        import urllib.request
        with urllib.request.urlopen(url) as response:
            data = json.loads(response.read().decode('utf-8'))
            
        if 'events' in data:
            segments = []
            for event in data['events']:
                if 'segs' in event:
                    text = ''.join([seg.get('utf8', '') for seg in event['segs']]).strip()
                    if text:
                        segments.append({
                            'text': text,
                            'start': event.get('tStartMs', 0) / 1000,
                            'duration': event.get('dDurationMs', 0) / 1000
                        })
            return segments
        return None
    except Exception as e:
        print(f"   âš ï¸ è·å–å­—å¹• URL å¤±è´¥: {str(e)}")
        return None

def extract_subtitles_with_playwright(video_id, cookies_base64=None):
    """ä½¿ç”¨ Playwright çœŸå®æµè§ˆå™¨æå–å­—å¹•"""
    try:
        from playwright.sync_api import sync_playwright
        import base64
        
        print(f"   ğŸ­ å¯åŠ¨ Playwright æµè§ˆå™¨...")
        
        with sync_playwright() as p:
            # å¯åŠ¨ Chromium
            browser = p.chromium.launch(headless=True)
            
            # åˆ›å»ºä¸Šä¸‹æ–‡
            context_options = {
                'user_agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
                'viewport': {'width': 1920, 'height': 1080},
                'locale': 'en-US',
            }
            
            # å¦‚æœæœ‰ cookiesï¼Œæ·»åŠ åˆ°ä¸Šä¸‹æ–‡
            if cookies_base64:
                try:
                    cookies_text = base64.b64decode(cookies_base64).decode('utf-8')
                    # è§£æ Netscape cookies æ ¼å¼å¹¶è½¬æ¢ä¸º Playwright æ ¼å¼
                    cookies = []
                    for line in cookies_text.split('\n'):
                        if line and not line.startswith('#'):
                            parts = line.split('\t')
                            if len(parts) >= 7:
                                cookies.append({
                                    'name': parts[5],
                                    'value': parts[6],
                                    'domain': parts[0],
                                    'path': parts[2],
                                    'expires': int(parts[4]) if parts[4] != '0' else -1,
                                    'httpOnly': parts[1] == 'TRUE',
                                    'secure': parts[3] == 'TRUE',
                                })
                    context_options['cookies'] = cookies
                    print(f"   ğŸª å·²åŠ è½½ {len(cookies)} ä¸ª cookies")
                except Exception as e:
                    print(f"   âš ï¸  Cookies è§£æå¤±è´¥: {e}")
            
            context = browser.new_context(**context_options)
            page = context.new_page()
            
            # è®¿é—® YouTube è§†é¢‘
            url = f"https://www.youtube.com/watch?v={video_id}"
            print(f"   ğŸŒ è®¿é—®: {url}")
            page.goto(url, wait_until='networkidle', timeout=30000)
            
            # ç­‰å¾…é¡µé¢åŠ è½½
            page.wait_for_timeout(3000)
            
            # å°è¯•æå–å­—å¹•æ•°æ®
            subtitles = page.evaluate('''() => {
                try {
                    // ä» ytInitialPlayerResponse æå–å­—å¹•
                    const playerResponse = window.ytInitialPlayerResponse;
                    if (!playerResponse || !playerResponse.captions) {
                        return null;
                    }
                    
                    const captionTracks = playerResponse.captions.playerCaptionsTracklistRenderer.captionTracks;
                    if (!captionTracks || captionTracks.length === 0) {
                        return null;
                    }
                    
                    // ä¼˜å…ˆé€‰æ‹©è‹±è¯­å­—å¹•
                    let track = captionTracks.find(t => t.languageCode === 'en') || captionTracks[0];
                    return track.baseUrl;
                } catch (e) {
                    return null;
                }
            }''')
            
            browser.close()
            
            if subtitles:
                print(f"   âœ… è·å–åˆ°å­—å¹• URL")
                # ä¸‹è½½å­—å¹•å†…å®¹
                return fetch_subtitle_from_url(subtitles)
            else:
                print(f"   âŒ æœªæ‰¾åˆ°å­—å¹•æ•°æ®")
                return None
                
    except Exception as e:
        print(f"   âŒ Playwright å¤±è´¥: {str(e)}")
        return None

@app.route("/", methods=["GET"])
def home():
    """å¥åº·æ£€æŸ¥ç«¯ç‚¹"""
    return jsonify({
        "status": "ok",
        "service": "DeepRead Subtitle API",
        "version": "1.0.0"
    })

@app.route("/extract", methods=["POST"])
def extract():
    """æå– YouTube å­—å¹• - ä½¿ç”¨åç«¯é…ç½®çš„ Cookie"""
    import os
    
    url = request.json.get("url", "")
    vid = get_video_id(url)
    
    if not vid:
        return jsonify({"error": "Invalid YouTube URL"}), 400

    # ä»ç¯å¢ƒå˜é‡è·å– YouTube Cookies
    youtube_cookies_raw = os.environ.get("YOUTUBE_COOKIES", "")
    youtube_cookies_base64 = os.environ.get("YOUTUBE_COOKIES_BASE64", "")
    
    # ä¼˜å…ˆä½¿ç”¨ Base64 ç¼–ç çš„ cookiesï¼ˆé¿å…æ¢è¡Œç¬¦é—®é¢˜ï¼‰
    youtube_cookies = ""
    if youtube_cookies_base64:
        try:
            import base64
            youtube_cookies = base64.b64decode(youtube_cookies_base64).decode('utf-8')
            print(f"ğŸ”“ ä½¿ç”¨ Base64 è§£ç çš„ Cookies")
        except Exception as e:
            print(f"âš ï¸  Base64 è§£ç å¤±è´¥: {e}")
    
    # å¦‚æœæ²¡æœ‰ Base64ï¼Œä½¿ç”¨åŸå§‹å€¼
    if not youtube_cookies and youtube_cookies_raw:
        youtube_cookies = youtube_cookies_raw
    
    try:
        print(f"\n{'='*60}")
        print(f"ğŸ¯ å¼€å§‹æå–å­—å¹•")
        print(f"ğŸ“¹ è§†é¢‘ ID: {vid}")
        print(f"ğŸª Cookies çŠ¶æ€: {'å·²é…ç½®' if youtube_cookies else 'æœªé…ç½®'}")
        if youtube_cookies:
            print(f"ğŸª Cookies é•¿åº¦: {len(youtube_cookies)} å­—ç¬¦")
            print(f"ğŸª Cookies å‰ 100 å­—ç¬¦: {youtube_cookies[:100]}")
        print(f"{'='*60}")
        
        # è·å–å®Œæ•´å­—å¹•ï¼ˆè‡ªåŠ¨ç¿»é¡µï¼‰
        segments = []
        page = 0
        e0 = None  # åˆå§‹åŒ–é”™è¯¯å˜é‡
        
        # ç­–ç•¥ 0: ä½¿ç”¨ Playwright çœŸå®æµè§ˆå™¨ï¼ˆæœ€å¼ºå¤§ï¼ï¼‰
        try:
            print(f"\nğŸ­ æ–¹æ³• 0: ä½¿ç”¨ Playwright çœŸå®æµè§ˆå™¨...")
            segments = extract_subtitles_with_playwright(vid, youtube_cookies_base64)
            
            if segments:
                print(f"âœ… Playwright æˆåŠŸ: {len(segments)} æ®µ")
            else:
                raise Exception("Playwright æœªæ‰¾åˆ°å­—å¹•")
                
        except Exception as e:
            e0 = e
            print(f"âŒ Playwright å¤±è´¥: {str(e0)}")
            segments = []
        
        # å¦‚æœ Playwright å¤±è´¥ï¼Œå°è¯•å…¶ä»–æ–¹æ³•
        e1 = None  # åˆå§‹åŒ–é”™è¯¯å˜é‡
        if not segments:
            # ç­–ç•¥ 1: ä½¿ç”¨ yt-dlp (æœ€å¼ºå¤§ï¼Œèƒ½ç»•è¿‡é™åˆ¶)
            try:
                print(f"\nğŸš€ æ–¹æ³• 1: ä½¿ç”¨ yt-dlp æå–å­—å¹•...")
                
                ydl_opts = {
                    'skip_download': True,
                    'writesubtitles': True,
                    'writeautomaticsub': True,
                    'subtitleslangs': ['en', 'en-US', 'en-GB'],
                    'subtitlesformat': 'json3',
                    'quiet': True,
                    'no_warnings': True,
                    # ä¼ªè£…æˆçœŸå®æµè§ˆå™¨
                    'user_agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
                    'referer': 'https://www.youtube.com/',
                    'headers': {
                        'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',
                        'Accept-Language': 'en-US,en;q=0.9',
                        'Accept-Encoding': 'gzip, deflate, br',
                        'DNT': '1',
                        'Connection': 'keep-alive',
                        'Upgrade-Insecure-Requests': '1',
                    },
                }
                
                # å¦‚æœé…ç½®äº† cookiesï¼Œå†™å…¥ä¸´æ—¶æ–‡ä»¶
                import tempfile
                import os as os_module
                cookie_file_path = None
                if youtube_cookies:
                    print(f"   ğŸª ä½¿ç”¨é…ç½®çš„ YouTube Cookies")
                    
                    # åˆ›å»ºä¸´æ—¶æ–‡ä»¶
                    fd, cookie_file_path = tempfile.mkstemp(suffix='.txt', text=True)
                    
                    # å†™å…¥ cookies
                    with os_module.fdopen(fd, 'w') as f:
                        f.write(youtube_cookies)
                        f.flush()
                    
                    print(f"   ğŸ“ Cookies æ–‡ä»¶å·²å†™å…¥: {cookie_file_path}")
                    
                    # éªŒè¯æ–‡ä»¶
                    with open(cookie_file_path, 'r') as f:
                        content = f.read()
                        lines = content.split('\n')
                        cookie_lines = [l for l in lines if l and not l.startswith('#')]
                        print(f"   âœ“ Cookie æ–‡ä»¶è¡Œæ•°: {len(lines)}ï¼Œæœ‰æ•ˆ cookie è¡Œæ•°: {len(cookie_lines)}")
                    
                    ydl_opts['cookiefile'] = cookie_file_path
                
                with yt_dlp.YoutubeDL(ydl_opts) as ydl:
                    info = ydl.extract_info(f"https://www.youtube.com/watch?v={vid}", download=False)
                    
                    # è·å–å­—å¹•
                    if 'subtitles' in info and info['subtitles']:
                        print(f"ğŸ“‹ æ‰¾åˆ°æ‰‹åŠ¨å­—å¹•: {list(info['subtitles'].keys())}")
                        # ä¼˜å…ˆä½¿ç”¨æ‰‹åŠ¨å­—å¹•
                        for lang in ['en', 'en-US', 'en-GB']:
                            if lang in info['subtitles']:
                                subtitle_url = info['subtitles'][lang][0]['url']
                                print(f"âœ… ä½¿ç”¨æ‰‹åŠ¨å­—å¹•: {lang}")
                                segments = fetch_subtitle_from_url(subtitle_url)
                                if segments:
                                    break
                    
                    elif 'automatic_captions' in info and info['automatic_captions']:
                        print(f"ğŸ“‹ æ‰¾åˆ°è‡ªåŠ¨å­—å¹•: {list(info['automatic_captions'].keys())}")
                        # ä½¿ç”¨è‡ªåŠ¨å­—å¹•
                        for lang in ['en', 'en-US', 'en-GB']:
                            if lang in info['automatic_captions']:
                                # æ‰¾åˆ° json3 æ ¼å¼çš„å­—å¹•
                                for subtitle in info['automatic_captions'][lang]:
                                    if subtitle.get('ext') == 'json3':
                                        subtitle_url = subtitle['url']
                                        print(f"âœ… ä½¿ç”¨è‡ªåŠ¨å­—å¹•: {lang}")
                                        segments = fetch_subtitle_from_url(subtitle_url)
                                        if segments:
                                            break
                                if segments:
                                    break
                    
                    if segments:
                        print(f"âœ… yt-dlp æˆåŠŸ: {len(segments)} æ®µ")
                    else:
                        raise Exception("yt-dlp æœªæ‰¾åˆ°å­—å¹•")
                
                # æ¸…ç†ä¸´æ—¶ cookie æ–‡ä»¶
                if cookie_file_path:
                    try:
                        os_module.unlink(cookie_file_path)
                        print(f"   ğŸ—‘ï¸  å·²æ¸…ç†ä¸´æ—¶ cookie æ–‡ä»¶")
                    except:
                        pass
                        
            except Exception as e:
                e1 = e
                print(f"âŒ yt-dlp å¤±è´¥: {str(e1)}")
                
                # ç­–ç•¥ 2: å¤‡ç”¨ youtube-transcript-api
                try:
                    print(f"\nğŸ”„ æ–¹æ³• 2: ä½¿ç”¨ youtube-transcript-api...")
                    transcript_list = YouTubeTranscriptApi.list_transcripts(vid)
                    
                    # ä¼˜å…ˆé€‰æ‹©è‹±è¯­å­—å¹•
                    selected_transcript = None
                    for transcript in transcript_list:
                        if transcript.language_code in ['en', 'en-US', 'en-GB']:
                            selected_transcript = transcript
                            break
                    
                    if not selected_transcript:
                        selected_transcript = list(transcript_list)[0]
                    
                    segments = selected_transcript.fetch()
                    print(f"âœ… youtube-transcript-api æˆåŠŸ: {len(segments)} æ®µ")
                    
                except Exception as e2:
                    error_msg = f"æ‰€æœ‰æ–¹æ³•éƒ½å¤±è´¥äº†ã€‚Playwright: {str(e0)}; yt-dlp: {str(e1)}; transcript-api: {str(e2)}"
                    print(f"\nâŒ {error_msg}")
                    return jsonify({"error": error_msg}), 404
        
        # æ ¼å¼åŒ–è¾“å‡º
        full_text = " ".join([s["text"] for s in segments])
        
        # æ ¼å¼åŒ–ä¸ºæ ‡å‡†æ ¼å¼
        formatted_segments = []
        for idx, seg in enumerate(segments):
            formatted_segments.append({
                "segment_id": f"seg_{str(idx).zfill(4)}",
                "start": seg["start"],
                "duration": seg["duration"],
                "end": seg["start"] + seg["duration"],
                "timestamp": format_timestamp(seg["start"]),
                "text": seg["text"]
            })
        
        # ç»Ÿè®¡ä¿¡æ¯
        total_duration = segments[-1]["start"] + segments[-1]["duration"] if segments else 0
        word_count = len(full_text.split())
        
        print(f"\n{'='*60}")
        print(f"âœ… æå–æˆåŠŸï¼")
        print(f"ğŸ“ æ€»æ®µæ•°: {len(formatted_segments)}")
        print(f"ğŸ’¬ æ€»å­—æ•°: {word_count}")
        print(f"â±ï¸  æ—¶é•¿: {format_timestamp(total_duration)}")
        print(f"{'='*60}\n")
        
        return jsonify({
            "success": True,
            "video_id": vid,
            "transcript": formatted_segments,
            "meta": {
                "segment_count": len(formatted_segments),
                "word_count": word_count,
                "duration_seconds": total_duration,
                "duration_formatted": format_timestamp(total_duration),
                "source": "youtube_transcript_api"
            }
        })
        
    except Exception as e:
        print(f"\nâŒ é”™è¯¯: {str(e)}\n")
        return jsonify({"error": str(e)}), 500

def format_timestamp(seconds):
    """æ ¼å¼åŒ–æ—¶é—´æˆ³"""
    hours = int(seconds // 3600)
    minutes = int((seconds % 3600) // 60)
    secs = int(seconds % 60)
    
    if hours > 0:
        return f"{hours}:{str(minutes).zfill(2)}:{str(secs).zfill(2)}"
    return f"{minutes}:{str(secs).zfill(2)}"

if __name__ == "__main__":
    # ç›‘å¬ 0.0.0.0 æ–¹ä¾¿å®¹å™¨è®¿é—®
    # Zeabur ä½¿ç”¨ 8080 ç«¯å£
    port = 8080
    print("\nğŸš€ DeepRead Subtitle API å¯åŠ¨ä¸­...")
    print(f"ğŸ“¡ ç›‘å¬ç«¯å£: {port}")
    print("="*60 + "\n")
    app.run(host="0.0.0.0", port=port, debug=False)

